{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå∏ Iris Flower Classifier\n",
    "\n",
    "**Project**: Classification of Iris flower species  \n",
    "**Level**: Beginner  \n",
    "**Dataset**: Iris Dataset (Scikit-learn built-in)  \n",
    "\n",
    "## üìã Project Overview\n",
    "\n",
    "In this project, we'll build a machine learning classifier to predict the species of iris flowers based on their physical characteristics. This is a classic beginner project that covers:\n",
    "\n",
    "- Data loading and exploration\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Data preprocessing\n",
    "- Multiple classification algorithms\n",
    "- Model evaluation and comparison\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration\n",
    "\n",
    "Let's load the famous Iris dataset and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target\n",
    "df['species_name'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(\"üìä Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {list(iris.feature_names)}\")\n",
    "print(f\"Target classes: {list(iris.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"üîç First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"üìà Dataset Information:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Features: {df.shape[1] - 2}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(\"\\nüìä Class distribution:\")\n",
    "print(df['species_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"üìä Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's visualize the data to understand the relationships between features and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plotting area\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('üå∏ Distribution of Iris Features by Species', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot distributions for each feature\n",
    "features = iris.feature_names\n",
    "for i, feature in enumerate(features):\n",
    "    row, col = i // 2, i % 2\n",
    "    \n",
    "    # Create histogram with species overlay\n",
    "    for species in df['species_name'].unique():\n",
    "        species_data = df[df['species_name'] == species][feature]\n",
    "        axes[row, col].hist(species_data, alpha=0.7, label=species, bins=15)\n",
    "    \n",
    "    axes[row, col].set_title(f'{feature.title()}', fontweight='bold')\n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].legend()\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot to see relationships between features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df, hue='species_name', markers=['o', 's', 'D'])\n",
    "plt.suptitle('üîç Pairwise Relationships Between Features', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[iris.feature_names].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('üî• Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç Key Observations:\")\n",
    "print(\"‚Ä¢ Petal length and petal width are highly correlated (0.96)\")\n",
    "print(\"‚Ä¢ Sepal length and petal length are moderately correlated (0.87)\")\n",
    "print(\"‚Ä¢ Sepal width has weak correlation with other features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Let's prepare our data for machine learning by splitting it and scaling the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df[iris.feature_names]  # Features\n",
    "y = df['species']           # Target\n",
    "\n",
    "print(\"üìä Data prepared:\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature names: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"‚úÇÔ∏è Data split completed:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚öñÔ∏è Feature scaling completed!\")\n",
    "print(f\"Original feature means: {X_train.mean().round(2).tolist()}\")\n",
    "print(f\"Scaled feature means: {X_train_scaled.mean(axis=0).round(2).tolist()}\")\n",
    "print(f\"Scaled feature stds: {X_train_scaled.std(axis=0).round(2).tolist()}\")\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Model Building and Training\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's train multiple classification algorithms and compare their performance.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize different classifiers\\n\",\n",
    "    \"models = {\\n\",\n",
    "    \"    'Logistic Regression': LogisticRegression(random_state=42),\\n\",\n",
    "    \"    'Decision Tree': DecisionTreeClassifier(random_state=42),\\n\",\n",
    "    \"    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\\n\",\n",
    "    \"    'Support Vector Machine': SVC(random_state=42)\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"ü§ñ Models initialized:\\\")\\n\",\n",
    "    \"for name in models.keys():\\n\",\n",
    "    \"    print(f\\\"‚Ä¢ {name}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train all models and store results\\n\",\n",
    "    \"results = {}\\n\",\n",
    "    \"trained_models = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üèãÔ∏è Training models...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for name, model in models.items():\\n\",\n",
    "    \"    print(f\\\"Training {name}...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Train the model\\n\",\n",
    "    \"    model.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Make predictions\\n\",\n",
    "    \"    y_pred = model.predict(X_test_scaled)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate accuracy\\n\",\n",
    "    \"    accuracy = accuracy_score(y_test, y_pred)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Cross-validation score\\n\",\n",
    "    \"    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Store results\\n\",\n",
    "    \"    results[name] = {\\n\",\n",
    "    \"        'accuracy': accuracy,\\n\",\n",
    "    \"        'cv_mean': cv_scores.mean(),\\n\",\n",
    "    \"        'cv_std': cv_scores.std(),\\n\",\n",
    "    \"        'predictions': y_pred\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    trained_models[name] = model\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"‚úÖ {name} - Accuracy: {accuracy:.4f}, CV Score: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüéâ All models trained successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Model Evaluation and Comparison\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's evaluate our models using various metrics and visualizations.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create a comparison DataFrame\\n\",\n",
    "    \"comparison_df = pd.DataFrame({\\n\",\n",
    "    \"    'Model': list(results.keys()),\\n\",\n",
    "    \"    'Test Accuracy': [results[model]['accuracy'] for model in results.keys()],\\n\",\n",
    "    \"    'CV Mean': [results[model]['cv_mean'] for model in results.keys()],\\n\",\n",
    "    \"    'CV Std': [results[model]['cv_std'] for model in results.keys()]\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"comparison_df = comparison_df.sort_values('Test Accuracy', ascending=False)\\n\",\n",
    "    \"print(\\\"üìä Model Performance Comparison:\\\")\\n\",\n",
    "    \"print(comparison_df.round(4))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize model performance\\n\",\n",
    "    \"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test Accuracy comparison\\n\",\n",
    "    \"bars1 = ax1.bar(comparison_df['Model'], comparison_df['Test Accuracy'], \\n\",\n",
    "    \"                color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\\n\",\n",
    "    \"ax1.set_title('üéØ Test Accuracy Comparison', fontweight='bold', fontsize=14)\\n\",\n",
    "    \"ax1.set_ylabel('Accuracy')\\n\",\n",
    "    \"ax1.set_ylim(0.8, 1.05)\\n\",\n",
    "    \"ax1.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add value labels on bars\\n\",\n",
    "    \"for bar in bars1:\\n\",\n",
    "    \"    height = bar.get_height()\\n\",\n",
    "    \"    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\\n\",\n",
    "    \"             f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Cross-validation scores with error bars\\n\",\n",
    "    \"bars2 = ax2.bar(comparison_df['Model'], comparison_df['CV Mean'], \\n\",\n",
    "    \"                yerr=comparison_df['CV Std'], capsize=5,\\n\",\n",
    "    \"                color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\\n\",\n",
    "    \"ax2.set_title('üìà Cross-Validation Scores', fontweight='bold', fontsize=14)\\n\",\n",
    "    \"ax2.set_ylabel('CV Score')\\n\",\n",
    "    \"ax2.set_ylim(0.8, 1.05)\\n\",\n",
    "    \"ax2.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add value labels on bars\\n\",\n",
    "    \"for bar in bars2:\\n\",\n",
    "    \"    height = bar.get_height()\\n\",\n",
    "    \"    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\\n\",\n",
    "    \"             f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
