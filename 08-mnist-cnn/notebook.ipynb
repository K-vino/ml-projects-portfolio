{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¢ MNIST Digit Classification with CNN\n",
    "\n",
    "**Project**: Deep Learning - Computer Vision  \n",
    "**Level**: Advanced  \n",
    "**Dataset**: MNIST Handwritten Digits  \n",
    "\n",
    "## üìã Project Overview\n",
    "\n",
    "This project classifies handwritten digits using Convolutional Neural Networks (CNN). We'll learn:\n",
    "\n",
    "- Deep learning fundamentals\n",
    "- CNN architecture design\n",
    "- Convolution and pooling operations\n",
    "- Data augmentation techniques\n",
    "- Model regularization and optimization\n",
    "\n",
    "Let's build our first deep learning model! üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Metrics and utilities\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üß† TensorFlow version: {tf.__version__}\")\n",
    "print(f\"üî• GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"üî¢ MNIST dataset loaded!\")\n",
    "print(f\"Training images: {X_train.shape}\")\n",
    "print(f\"Training labels: {y_train.shape}\")\n",
    "print(f\"Test images: {X_test.shape}\")\n",
    "print(f\"Test labels: {y_test.shape}\")\n",
    "print(f\"Image shape: {X_train[0].shape}\")\n",
    "print(f\"Pixel value range: {X_train.min()} - {X_train.max()}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample digits\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "fig.suptitle('üîç Sample MNIST Digits', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i in range(10):\n",
    "    row, col = i // 5, i % 5\n",
    "    \n",
    "    # Find first occurrence of digit i\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    \n",
    "    axes[row, col].imshow(X_train[idx], cmap='gray')\n",
    "    axes[row, col].set_title(f'Digit: {i}', fontweight='bold')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set distribution\n",
    "train_counts = np.bincount(y_train)\n",
    "axes[0].bar(range(10), train_counts, color='skyblue', alpha=0.7)\n",
    "axes[0].set_title('üìä Training Set - Digit Distribution', fontweight='bold', fontsize=14)\n",
    "axes[0].set_xlabel('Digit')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticks(range(10))\n",
    "\n",
    "# Add value labels\n",
    "for i, count in enumerate(train_counts):\n",
    "    axes[0].text(i, count + 50, str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Test set distribution\n",
    "test_counts = np.bincount(y_test)\n",
    "axes[1].bar(range(10), test_counts, color='lightcoral', alpha=0.7)\n",
    "axes[1].set_title('üìä Test Set - Digit Distribution', fontweight='bold', fontsize=14)\n",
    "axes[1].set_xlabel('Digit')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xticks(range(10))\n",
    "\n",
    "# Add value labels\n",
    "for i, count in enumerate(test_counts):\n",
    "    axes[1].text(i, count + 20, str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Dataset is well balanced across all digits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and normalize the data\n",
    "print(\"üîß Preprocessing data...\")\n",
    "\n",
    "# Reshape to add channel dimension (for CNN)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"‚úÖ Preprocessed training data shape: {X_train.shape}\")\n",
    "print(f\"‚úÖ Preprocessed test data shape: {X_test.shape}\")\n",
    "print(f\"‚úÖ Training labels shape: {y_train_cat.shape}\")\n",
    "print(f\"‚úÖ Test labels shape: {y_test_cat.shape}\")\n",
    "print(f\"‚úÖ Pixel value range: {X_train.min():.1f} - {X_train.max():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation setup\n",
    "print(\"üîÑ Setting up data augmentation...\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,      # Rotate images by up to 10 degrees\n",
    "    width_shift_range=0.1,  # Shift images horizontally by up to 10%\n",
    "    height_shift_range=0.1, # Shift images vertically by up to 10%\n",
    "    zoom_range=0.1,         # Zoom in/out by up to 10%\n",
    "    shear_range=0.1,        # Shear transformation\n",
    "    fill_mode='nearest'     # Fill strategy for new pixels\n",
    ")\n",
    "\n",
    "# Fit the data generator\n",
    "datagen.fit(X_train)\n",
    "\n",
    "print(\"‚úÖ Data augmentation configured!\")\n",
    "\n",
    "# Visualize augmented images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "fig.suptitle('üîÑ Data Augmentation Examples', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Take one sample image\n",
    "sample_image = X_train[0:1]  # Shape: (1, 28, 28, 1)\n",
    "\n",
    "# Generate augmented versions\n",
    "augmented_images = []\n",
    "for batch in datagen.flow(sample_image, batch_size=1):\n",
    "    augmented_images.append(batch[0])\n",
    "    if len(augmented_images) >= 10:\n",
    "        break\n",
    "\n",
    "for i in range(10):\n",
    "    row, col = i // 5, i % 5\n",
    "    axes[row, col].imshow(augmented_images[i].squeeze(), cmap='gray')\n",
    "    axes[row, col].set_title(f'Augmented {i+1}', fontweight='bold')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "print(\"üèóÔ∏è Building CNN architecture...\")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Flatten and Dense Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ CNN model built and compiled!\")\n",
    "print(\"\\nüìã Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model architecture\n",
    "print(\"üé® Model Architecture Visualization:\")\n",
    "\n",
    "# Create a simple text representation\n",
    "print(\"\"\"\n",
    "üß† CNN Architecture Flow:\n",
    "\n",
    "Input (28√ó28√ó1) \n",
    "    ‚Üì\n",
    "Conv2D (32 filters, 3√ó3) + ReLU + BatchNorm\n",
    "    ‚Üì\n",
    "Conv2D (32 filters, 3√ó3) + ReLU\n",
    "    ‚Üì\n",
    "MaxPooling (2√ó2) + Dropout (0.25)\n",
    "    ‚Üì\n",
    "Conv2D (64 filters, 3√ó3) + ReLU + BatchNorm\n",
    "    ‚Üì\n",
    "Conv2D (64 filters, 3√ó3) + ReLU\n",
    "    ‚Üì\n",
    "MaxPooling (2√ó2) + Dropout (0.25)\n",
    "    ‚Üì\n",
    "Conv2D (128 filters, 3√ó3) + ReLU + BatchNorm + Dropout (0.25)\n",
    "    ‚Üì\n",
    "Flatten\n",
    "    ‚Üì\n",
    "Dense (512) + ReLU + BatchNorm + Dropout (0.5)\n",
    "    ‚Üì\n",
    "Dense (10) + Softmax\n",
    "    ‚Üì\n",
    "Output (10 classes)\n",
    "\"\"\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = model.count_params()\n",
    "print(f\"üìä Total Parameters: {total_params:,}\")\n",
    "print(f\"üìä Model Size: ~{total_params * 4 / 1024 / 1024:.1f} MB (float32)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
