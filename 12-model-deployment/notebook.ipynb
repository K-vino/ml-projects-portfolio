{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ ML Model Deployment\n",
    "\n",
    "**Project**: Model Deployment and Production ML  \n",
    "**Level**: Expert  \n",
    "**Frameworks**: Flask, Streamlit, FastAPI, Docker  \n",
    "\n",
    "## üìã Project Overview\n",
    "\n",
    "This project demonstrates how to deploy machine learning models to production using various frameworks and deployment strategies. We'll learn:\n",
    "\n",
    "- Building REST APIs with Flask and FastAPI\n",
    "- Creating interactive dashboards with Streamlit\n",
    "- Containerization with Docker\n",
    "- Cloud deployment strategies\n",
    "- MLOps best practices\n",
    "\n",
    "Let's deploy our models to production! üåê"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Web frameworks (for demonstration)\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Utilities\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üöÄ Ready for model deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "print(\"üìä Loading Iris dataset...\")\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {list(iris.feature_names)}\")\n",
    "print(f\"Classes: {list(iris.target_names)}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Train model\n",
    "print(\"\\nü§ñ Training Random Forest model...\")\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=5\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "train_accuracy = model.score(X_train, y_train)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f\"‚úÖ Model trained successfully!\")\n",
    "print(f\"Training accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': iris.feature_names,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.title('üåü Feature Importance in Random Forest Model', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç Feature Importance Ranking:\")\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"‚Ä¢ {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Serialization and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "print(\"üíæ Saving model and metadata...\")\n",
    "\n",
    "# Save model using joblib (recommended for scikit-learn)\n",
    "joblib.dump(model, 'models/iris_model.pkl')\n",
    "print(\"‚úÖ Model saved as 'iris_model.pkl'\")\n",
    "\n",
    "# Save feature names\n",
    "with open('models/feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(iris.feature_names, f)\n",
    "print(\"‚úÖ Feature names saved\")\n",
    "\n",
    "# Save target names\n",
    "with open('models/target_names.pkl', 'wb') as f:\n",
    "    pickle.dump(iris.target_names, f)\n",
    "print(\"‚úÖ Target names saved\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'train_accuracy': float(train_accuracy),\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'n_features': len(iris.feature_names),\n",
    "    'n_classes': len(iris.target_names),\n",
    "    'feature_names': list(iris.feature_names),\n",
    "    'target_names': list(iris.target_names),\n",
    "    'model_params': model.get_params()\n",
    "}\n",
    "\n",
    "with open('models/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"‚úÖ Model metadata saved\")\n",
    "\n",
    "# Check file sizes\n",
    "model_size = os.path.getsize('models/iris_model.pkl') / 1024  # KB\n",
    "print(f\"\\nüìä Model file size: {model_size:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loading\n",
    "print(\"üîÑ Testing model loading...\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = joblib.load('models/iris_model.pkl')\n",
    "\n",
    "# Load metadata\n",
    "with open('models/metadata.json', 'r') as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "\n",
    "# Test prediction\n",
    "test_sample = X_test[0:1]  # First test sample\n",
    "original_pred = model.predict(test_sample)[0]\n",
    "loaded_pred = loaded_model.predict(test_sample)[0]\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"Original prediction: {iris.target_names[original_pred]}\")\n",
    "print(f\"Loaded model prediction: {iris.target_names[loaded_pred]}\")\n",
    "print(f\"Predictions match: {original_pred == loaded_pred}\")\n",
    "\n",
    "print(f\"\\nüìã Loaded Metadata:\")\n",
    "for key, value in loaded_metadata.items():\n",
    "    if key != 'model_params':  # Skip detailed params for readability\n",
    "        print(f\"‚Ä¢ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. API Testing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample prediction function (simulating API)\n",
    "def predict_species(features, model=loaded_model, target_names=iris.target_names):\n",
    "    \"\"\"\n",
    "    Simulate API prediction function\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input\n",
    "        if len(features) != 4:\n",
    "            return {'error': f'Expected 4 features, got {len(features)}'}\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        features_array = np.array(features).reshape(1, -1)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(features_array)[0]\n",
    "        prediction_proba = model.predict_proba(features_array)[0]\n",
    "        \n",
    "        # Prepare response\n",
    "        response = {\n",
    "            'prediction': int(prediction),\n",
    "            'prediction_label': target_names[prediction],\n",
    "            'probabilities': {\n",
    "                target_names[i]: float(prob) \n",
    "                for i, prob in enumerate(prediction_proba)\n",
    "            },\n",
    "            'confidence': float(max(prediction_proba)),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# Test with different examples\n",
    "test_cases = [\n",
    "    {\n",
    "        'name': 'Typical Setosa',\n",
    "        'features': [5.1, 3.5, 1.4, 0.2],\n",
    "        'expected': 'setosa'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Typical Versicolor',\n",
    "        'features': [5.7, 2.8, 4.1, 1.3],\n",
    "        'expected': 'versicolor'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Typical Virginica',\n",
    "        'features': [6.2, 2.8, 4.8, 1.8],\n",
    "        'expected': 'virginica'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing API prediction function...\\n\")\n",
    "\n",
    "for test_case in test_cases:\n",
    "    result = predict_species(test_case['features'])\n",
    "    \n",
    "    print(f\"üìù Test: {test_case['name']}\")\n",
    "    print(f\"   Input: {test_case['features']}\")\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"   ‚ùå Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"   üéØ Prediction: {result['prediction_label']}\")\n",
    "        print(f\"   üìä Confidence: {result['confidence']:.1%}\")\n",
    "        print(f\"   ‚úÖ Correct: {result['prediction_label'] == test_case['expected']}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deployment Strategies Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display deployment options\n",
    "deployment_options = {\n",
    "    'Flask REST API': {\n",
    "        'description': 'Simple web API for model predictions',\n",
    "        'use_case': 'Backend service for applications',\n",
    "        'pros': ['Simple', 'Lightweight', 'Flexible'],\n",
    "        'cons': ['Manual scaling', 'Basic features']\n",
    "    },\n",
    "    'Streamlit Dashboard': {\n",
    "        'description': 'Interactive web application',\n",
    "        'use_case': 'Business dashboards and demos',\n",
    "        'pros': ['No web dev needed', 'Interactive', 'Fast prototyping'],\n",
    "        'cons': ['Limited customization', 'Not for APIs']\n",
    "    },\n",
    "    'FastAPI Service': {\n",
    "        'description': 'High-performance async API',\n",
    "        'use_case': 'Production microservices',\n",
    "        'pros': ['Fast', 'Auto docs', 'Type validation'],\n",
    "        'cons': ['More complex', 'Learning curve']\n",
    "    },\n",
    "    'Docker Container': {\n",
    "        'description': 'Containerized deployment',\n",
    "        'use_case': 'Cloud deployment and scaling',\n",
    "        'pros': ['Portable', 'Scalable', 'Consistent'],\n",
    "        'cons': ['Container overhead', 'Complexity']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üöÄ Deployment Options Overview:\\n\")\n",
    "\n",
    "for option, details in deployment_options.items():\n",
    "    print(f\"üì¶ {option}\")\n",
    "    print(f\"   Description: {details['description']}\")\n",
    "    print(f\"   Use Case: {details['use_case']}\")\n",
    "    print(f\"   Pros: {', '.join(details['pros'])}\")\n",
    "    print(f\"   Cons: {', '.join(details['cons'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Production Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production checklist\n",
    "production_checklist = {\n",
    "    'üîí Security': [\n",
    "        'API authentication and authorization',\n",
    "        'Input validation and sanitization',\n",
    "        'HTTPS encryption',\n",
    "        'Rate limiting and DDoS protection'\n",
    "    ],\n",
    "    'üìä Monitoring': [\n",
    "        'Request/response logging',\n",
    "        'Performance metrics (latency, throughput)',\n",
    "        'Model drift detection',\n",
    "        'Error tracking and alerting'\n",
    "    ],\n",
    "    '‚ö° Performance': [\n",
    "        'Response time optimization',\n",
    "        'Caching strategies',\n",
    "        'Load balancing',\n",
    "        'Auto-scaling configuration'\n",
    "    ],\n",
    "    'üîÑ Reliability': [\n",
    "        'Health checks and heartbeats',\n",
    "        'Graceful error handling',\n",
    "        'Circuit breakers',\n",
    "        'Backup and recovery plans'\n",
    "    ],\n",
    "    'üß™ Testing': [\n",
    "        'Unit tests for prediction logic',\n",
    "        'Integration tests for API endpoints',\n",
    "        'Load testing for performance',\n",
    "        'A/B testing for model versions'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Production Deployment Checklist:\\n\")\n",
    "\n",
    "for category, items in production_checklist.items():\n",
    "    print(f\"{category}\")\n",
    "    for item in items:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps and Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display next steps\n",
    "next_steps = {\n",
    "    'üöÄ Immediate Actions': [\n",
    "        'Run the Flask app: python app.py',\n",
    "        'Launch Streamlit: streamlit run streamlit_app.py',\n",
    "        'Build Docker image: docker build -t ml-api .',\n",
    "        'Test API endpoints with curl or Postman'\n",
    "    ],\n",
    "    '‚òÅÔ∏è Cloud Deployment': [\n",
    "        'Deploy to Heroku for quick hosting',\n",
    "        'Use AWS ECS/Fargate for containers',\n",
    "        'Try Google Cloud Run for serverless',\n",
    "        'Explore Azure Container Instances'\n",
    "    ],\n",
    "    'üîß Advanced Features': [\n",
    "        'Add model versioning with MLflow',\n",
    "        'Implement A/B testing framework',\n",
    "        'Set up CI/CD pipelines',\n",
    "        'Add real-time monitoring dashboards'\n",
    "    ],\n",
    "    'üìö Learning Resources': [\n",
    "        'MLOps: Machine Learning Operations',\n",
    "        'Kubernetes for ML workloads',\n",
    "        'Model serving with TensorFlow Serving',\n",
    "        'Monitoring with Prometheus and Grafana'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üéØ Next Steps and Recommendations:\\n\")\n",
    "\n",
    "for category, items in next_steps.items():\n",
    "    print(f\"{category}\")\n",
    "    for item in items:\n",
    "        print(f\"   ‚Ä¢ {item}\")\n",
    "    print()\n",
    "\n",
    "print(\"üéâ Congratulations! You've completed the ML Model Deployment project!\")\n",
    "print(\"üöÄ Your model is now ready for production deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
